{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be15969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# from https://www.kaggle.com/vipulgandhi/a-comprehensive-guide-to-ensemble-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0f3b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90c8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment_tenure</th>\n",
       "      <th>gross_monthly_income</th>\n",
       "      <th>loan_release_date</th>\n",
       "      <th>loan_release_mo</th>\n",
       "      <th>loan_release_year</th>\n",
       "      <th>payroll_cut-off</th>\n",
       "      <th>periodic_payment</th>\n",
       "      <th>...</th>\n",
       "      <th>_dpd2</th>\n",
       "      <th>_pd90</th>\n",
       "      <th>bucket</th>\n",
       "      <th>restructured_nov_30</th>\n",
       "      <th>_active_pd</th>\n",
       "      <th>status</th>\n",
       "      <th>_new_seasoned</th>\n",
       "      <th>delinquent_reason</th>\n",
       "      <th>last_repayment_paid_nov_20</th>\n",
       "      <th>principal_oustanding_par90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LN096458</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>WNS GLOBAL SERVICES</td>\n",
       "      <td>9</td>\n",
       "      <td>23764</td>\n",
       "      <td>12/30/2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>13 AND 29</td>\n",
       "      <td>1729.22</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>SEPARATED</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1/13/2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LN053391</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>IBIDEN PHILS</td>\n",
       "      <td>6</td>\n",
       "      <td>23868</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>10 AND 25</td>\n",
       "      <td>2163.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10/25/2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LN096940</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>METRO COMBINED LOGISTICS SOLUTIONS, INC.</td>\n",
       "      <td>11</td>\n",
       "      <td>53300</td>\n",
       "      <td>1/12/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 AND 20</td>\n",
       "      <td>4437.67</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10/25/2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_number          loan_type                                  employer  \\\n",
       "0    LN096458  LOAN ORIGINATIONS                       WNS GLOBAL SERVICES   \n",
       "1    LN053391  LOAN ORIGINATIONS                              IBIDEN PHILS   \n",
       "2    LN096940  LOAN ORIGINATIONS  METRO COMBINED LOGISTICS SOLUTIONS, INC.   \n",
       "\n",
       "   employment_tenure  gross_monthly_income loan_release_date  loan_release_mo  \\\n",
       "0                  9                 23764        12/30/2020               12   \n",
       "1                  6                 23868         1/13/2021                1   \n",
       "2                 11                 53300         1/12/2021                1   \n",
       "\n",
       "   loan_release_year payroll_cut-off  periodic_payment  ...     _dpd2  \\\n",
       "0               2020       13 AND 29           1729.22  ...   Current   \n",
       "1               2021       10 AND 25           2163.33  ...   Current   \n",
       "2               2021        5 AND 20           4437.67  ...   Current   \n",
       "\n",
       "              _pd90    bucket  restructured_nov_30  _active_pd      status  \\\n",
       "0  less than 90dpd\\   Current                    N      Active   SEPARATED   \n",
       "1  less than 90dpd\\   Current                    N      Active     CURRENT   \n",
       "2  less than 90dpd\\   Current                    N      Active     CURRENT   \n",
       "\n",
       "   _new_seasoned delinquent_reason last_repayment_paid_nov_20  \\\n",
       "0       New Loan           unknown                  1/13/2022   \n",
       "1       New Loan           unknown                 10/25/2021   \n",
       "2       New Loan           unknown                 10/25/2021   \n",
       "\n",
       "  principal_oustanding_par90  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_uploan_nov2021.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39f5330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select col types\n",
    "cols_cat = df.select_dtypes(include='object').columns\n",
    "cols_num = df.select_dtypes(include='number').columns\n",
    "\n",
    "cols_X = ['employer', 'employment_tenure','gross_monthly_income', \n",
    "     'loan_release_mo', 'loan_release_year', 'payroll_cut-off', 'periodic_payment',\n",
    "       'total_payable_assumed_balance', 'total_principal', 'total_interest',\n",
    "       'no_of_remaining_repayments', 'outstanding_bal_nov_20', 'principal',\n",
    "       'interest']\n",
    "cols_y = ['target']\n",
    "\n",
    "# Label encoding\n",
    "ln_loan_type = LabelEncoder()\n",
    "ln_employer = LabelEncoder()\n",
    "ln_payroll = LabelEncoder()\n",
    "\n",
    "df['loan_type'] = ln_loan_type.fit_transform(df['loan_type'])\n",
    "df['employer'] = ln_employer.fit_transform(df['employer'])\n",
    "df['payroll_cut-off'] = ln_payroll.fit_transform(df['payroll_cut-off'])\n",
    "\n",
    "# Select X and y\n",
    "X  = df[cols_X]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58dbd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numeric\n",
    "ln_target = LabelEncoder()\n",
    "y = ln_target.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "974252e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3d0d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 180, 0: 49, 1: 36})\n",
      "Counter({2: 46, 0: 12, 1: 9})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b912175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "fit_scaler_X_test = scaler_test.fit(X_test)\n",
    "fit_scaler_X_train = scaler_train.fit(X_train)\n",
    "\n",
    "X_test_scaled = fit_scaler_X_test.transform(X_test)\n",
    "X_train_scaled = fit_scaler_X_train.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4eee4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164179104477612\n",
      "Feature Importance:\n",
      "employer 0.11720558267413946\n",
      "employment_tenure 0.08155488964468935\n",
      "gross_monthly_income 0.04146031402187824\n",
      "loan_release_mo 0.03847925041163239\n",
      "loan_release_year 0.010766755124965692\n",
      "payroll_cut-off 0.054076522383988926\n",
      "periodic_payment 0.060437028160277906\n",
      "total_payable_assumed_balance 0.08435470964960833\n",
      "total_principal 0.060570438422571794\n",
      "total_interest 0.15648496154440814\n",
      "no_of_remaining_repayments 0.06318784697217597\n",
      "outstanding_bal_nov_20 0.08447978835459351\n",
      "principal 0.054575886218060865\n",
      "interest 0.09236602641700957\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Random Forest is an ensemble of Decision Trees.\n",
    "# If we look at a single Decision Tree, important features are likely to appear closer to the root of the \n",
    "# tree, while unimportant features will often appear closer to the leaves (or not at all). It is possible \n",
    "# to get an estimate of a featureâ€™s importance by computing the average depth at which it appears across all \n",
    "# trees in the forest.\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# Feature importance\n",
    "print('Feature Importance:')\n",
    "for name, score in zip(X.columns, model_rf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa9eaded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5970149253731343\n",
      "Feature Importance:\n",
      "employer 0.075\n",
      "employment_tenure 0.02\n",
      "gross_monthly_income 0.035\n",
      "loan_release_mo 0.055\n",
      "loan_release_year 0.04\n",
      "payroll_cut-off 0.015\n",
      "periodic_payment 0.13\n",
      "total_payable_assumed_balance 0.04\n",
      "total_principal 0.065\n",
      "total_interest 0.225\n",
      "no_of_remaining_repayments 0.065\n",
      "outstanding_bal_nov_20 0.03\n",
      "principal 0.105\n",
      "interest 0.1\n"
     ]
    }
   ],
   "source": [
    "# Ada Boost\n",
    "# Boosting refers to a family of algorithms that are able to convert weak learners to strong learners. \n",
    "# The main principle of boosting is to fit a sequence of weak learnersâˆ’ models that are only slightly \n",
    "# better than random guessing, such as small decision trees to weighted versions of the data. More weight \n",
    "# is given to examples that were misclassified by earlier rounds.\n",
    "# The predictions are then combined through a weighted majority vote (classification) or a weighted sum (regression)\n",
    "# to produce the final prediction.\n",
    "\n",
    "# Boosting technique cannot be parallelized (or only partially) because each predictor can only be trained after \n",
    "# the previous predictor has been trained and evaluated. As a result, it does not scale as well as bagging / pasting.\n",
    "\n",
    "# The predictors(classifier/ regressor) fit the training set in sequence. The next predictor corrects its predecessor \n",
    "# by paying more attention to the training instances that the predecessor underfitted. This results in new predictors \n",
    "# focusing more and more on the hard cases.\n",
    "\n",
    "# To build an AdaBoost classifier, each instance's weight is set to an initial value. A base classifier (eg. Decision Tree)\n",
    "# is trained and makes predictions on the training set. The relative weight of misclassified training instances is then \n",
    "# increased. The second classifier is trained on the training set using the updated weights and again it makes predictions\n",
    "# on the training set and update the weights. The algorithm stops when the desired number of predictors is reached, or\n",
    "# when a perfect predictor is found.\n",
    "\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "model_ada.fit(X_train, y_train)\n",
    "y_pred_ada = model_ada.predict(X_test)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, y_pred_ada))\n",
    "\n",
    "# Feature importance\n",
    "print('Feature Importance:')\n",
    "for name, score in zip(X.columns, model_ada.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1f21b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "# Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. \n",
    "# However, instead of tweaking the instance weights at every iteration like AdaBoost, Gradient Boosting tries to \n",
    "# fit the new predictor to the residual errors made by the previous predictor.\n",
    "\n",
    "model_gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "model_gbrt.fit(X_train, y_train)\n",
    "\n",
    "# ...read thru gbr further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "26a4cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(n_estimators=10, random_state=1)\n",
      "Training the ExtraTreesClassifier(n_estimators=10, random_state=1)\n",
      "Training the AdaBoostClassifier(learning_rate=0.5, n_estimators=200)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.7611940298507462\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "# Stacking is an ensemble learning technique that uses predictions from multiple models \n",
    "# (for example decision tree, knn or svm) to build a new model. This model is used for making \n",
    "# predictions on the test set.\n",
    "\n",
    "# First, the training set is split in two subsets. The first subset is used to train the predictors in the first \n",
    "# layer. Next, the predictors in the first layer are used to make predictions on the second(hold-out) set. \n",
    "# Now (in example above) for each instance in the hold-out set there are four predicted values. A new \n",
    "# training set is created using these predicted values as input features and keeping the target values. \n",
    "# The blender is trained on this new training set, it learns to predict the target value where inputs are \n",
    "# the the first layerâ€™s predictions.\n",
    "\n",
    "# It is possible to train several different blenders on the top of one another (e.g., one using Linear \n",
    "# Regression, another using Random Forest Regression etc). The training set should be divided equal to the number of layers(see image above).\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "model_et = ExtraTreesClassifier(n_estimators=10, random_state=1)\n",
    "model_ada = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "# mlp_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "estimators = [model_rf, model_et, model_ada]\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "\n",
    "[estimator.score(X_test, y_test) for estimator in estimators]\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "\n",
    "model_rf_blend = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "model_rf_blend.fit(X_test_predictions, y_test)\n",
    "\n",
    "print('OOB Score: %s' %model_rf_blend.oob_score_)\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_pred = model_rf_blend.predict(X_test_predictions)\n",
    "print('Accuracy Score: %s' %accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b291a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.49336356429261485\n",
      "R2: 0.18875126735914005\n"
     ]
    }
   ],
   "source": [
    "# Linear Model\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_ln = linear_model.LinearRegression()\n",
    "model_ln.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "predict_ln = model_ln.predict(X_test)\n",
    "\n",
    "print('MSE: %s' %mean_squared_error(y_test, predict_ln))\n",
    "print('R2: %s' %r2_score(y_test, predict_ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad75e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.18746924869674975\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Cannot handle multi-class\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_ridge = linear_model.Ridge(alpha=0.5)\n",
    "print('Score: {}'.format(model_ridge.fit(X_train, y_train).score(X_test, y_test)))\n",
    "\n",
    "predict_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "model_ridge.coef_\n",
    "\n",
    "# RidgeCV implements ridge regression with built-in cross-validation of the alpha parameter. \n",
    "# The object works in the same way as GridSearchCV except that it defaults to Leave-One-Out Cross-Validation:\n",
    "\n",
    "model_ridge_cv = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "model_ridge_cv.fit(X_train, y_train).score(X_test, y_test)\n",
    "model_ridge_cv.alpha_\n",
    "np.logspace(-6, 6, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e34164a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7164179104477612\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-5113ed67dd72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpredict_ridge_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ridge_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_ridge_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mmodel_ridge_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier!!!\n",
    "#...fit transform first...\n",
    "\n",
    "model_ridge_clf = linear_model.RidgeClassifier()\n",
    "print(model_ridge_clf.fit(X_train_scaled, y_train).score(X_test_scaled, y_test))\n",
    "\n",
    "predict_ridge_clf = model_ridge_clf.predict(X_test_scaled)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, predict_ridge_clf))\n",
    "model_ridge_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dd1e996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_sgb    0    1     2\n",
      "actual                     \n",
      "0            5.0  1.0   6.0\n",
      "1            1.0  2.0   6.0\n",
      "2            NaN  5.0  41.0\n",
      "\n",
      "predict_ridge_clf    0     2\n",
      "actual                      \n",
      "0                  2.0  10.0\n",
      "1                  NaN   9.0\n",
      "2                  NaN  46.0\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent on Linear Models\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "model_sgb = make_pipeline(scaler, linear_model.SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model_sgb.fit(X_train, y_train).score(X_test, y_test)\n",
    "predict_sgb = model_sgb.predict(X_test)\n",
    "\n",
    "model_ridge_clf = make_pipeline(scaler, linear_model.RidgeClassifier())\n",
    "model_ridge_clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "predict_ridge_clf = model_ridge_clf.predict(X_test)\n",
    "\n",
    "cols = ['predict_sgb','predict_ridge_clf']\n",
    "foo = pd.DataFrame(zip(predict_sgb, predict_ridge_clf, y_test))\n",
    "foo.rename(columns={0:'predict_sgb', 1:'predict_ridge_clf',2:'actual'}, inplace=True)\n",
    "\n",
    "print(pd.crosstab(foo['actual'], [foo['predict_sgb']], aggfunc='count', values='actual'))\n",
    "print('')\n",
    "print(pd.crosstab(foo['actual'], [foo['predict_ridge_clf']], aggfunc='count', values='actual'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a88e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 0.35714286, 0.46153846, 0.53846154, 0.76923077])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model_per = make_pipeline(linear_model.Perceptron(random_state=1))\n",
    "model_per.fit(X_train_scaled, y_train).score(X_test_scaled, y_test)\n",
    "\n",
    "cross_val_score(model_per, X_test_scaled, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fad3a089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_per</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual         0    1     2\n",
       "predict_per                \n",
       "0            5.0  1.0   8.0\n",
       "1            NaN  1.0   8.0\n",
       "2            7.0  7.0  30.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_per = pd.DataFrame(cross_val_predict(model_per, X_test_scaled, y_test), columns=['predict_per'])\n",
    "foo = pd.concat([predict_per, pd.Series(y_test)], axis=1)\n",
    "foo.rename(columns={0:'actual'}, inplace=True)\n",
    "pd.crosstab(foo['predict_per'], foo['actual'], aggfunc='count', values='actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8461f61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7511111111111112"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polynomial regression: extending linear models with basis functionsÂ¶\n",
    "# One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. \n",
    "# This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider\n",
    "# range of data. For example, a simple linear regression can be extended by constructing polynomial features \n",
    "# from the coefficients. In the standard linear regression case, you might have a model that looks like this \n",
    "# for two-dimensional data:\n",
    "\n",
    "a = pd.Series([1,2,3,4,5,4,3,2,1,0])\n",
    "b = pd.Series([0,0,1,1,1,1,1,0,0,0])\n",
    "foo = pd.concat([a,b], axis=1)\n",
    "foo.rename(columns={0:'a',1:'b'}, inplace=True)\n",
    "a = foo[['a']]\n",
    "b = foo.b\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "model_ln_poly = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                               ('model_ln',LinearRegression())])\n",
    "model_ln_poly.fit(a,b).score(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8ddff621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313432835820896"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA and QDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda.fit(X_train, y_train).score(X_test, y_test)\n",
    "model_lda.coef_\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_e1 = make_pipeline(LinearDiscriminantAnalysis(), linear_model.RidgeClassifier())\n",
    "model_e1.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bed3c01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7761194029850746"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d692cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 14 features, but RandomForestClassifier is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-338aa2b7923d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_rf_blend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    567\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    568\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    396\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 14 features, but RandomForestClassifier is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "from scipy.stats import describe\n",
    "describe(my_score)\n",
    "model_rf_blend.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c9a5af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(n_estimators=10, random_state=1)\n",
      "Training the ExtraTreesClassifier(n_estimators=10, random_state=1)\n",
      "Training the AdaBoostClassifier(learning_rate=0.5, n_estimators=200)\n",
      "Training the MLPClassifier(random_state=9)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define models    \n",
    "model_rf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "model_et = ExtraTreesClassifier(n_estimators=10, random_state=1)\n",
    "model_ada = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "mlp_clf = MLPClassifier(random_state=i)\n",
    "\n",
    "# Create estimators\n",
    "estimators = [model_rf, model_et, model_ada, mlp_clf]\n",
    "\n",
    "# Fit each estimator\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "\n",
    "[estimator.score(X_test, y_test) for estimator in estimators]\n",
    "\n",
    "# Create X_test_predictions to be used by model_rf_blend below\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "\n",
    "# Fit    \n",
    "model_rf_blend = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "model_rf_blend.fit(X_test_predictions, y_test)\n",
    "model_rf_blend.predict(X_test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1fab282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6865671641791045"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For predicting...\n",
    "\n",
    "# Predict first row of X_test\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test.iloc[[50]])\n",
    "\n",
    "y_pred = model_rf_blend.predict(X_test_predictions)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3fe14c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employer</th>\n",
       "      <th>employment_tenure</th>\n",
       "      <th>gross_monthly_income</th>\n",
       "      <th>loan_release_mo</th>\n",
       "      <th>loan_release_year</th>\n",
       "      <th>payroll_cut-off</th>\n",
       "      <th>periodic_payment</th>\n",
       "      <th>total_payable_assumed_balance</th>\n",
       "      <th>total_principal</th>\n",
       "      <th>total_interest</th>\n",
       "      <th>no_of_remaining_repayments</th>\n",
       "      <th>outstanding_bal_nov_20</th>\n",
       "      <th>principal</th>\n",
       "      <th>interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>56500</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>4550.64</td>\n",
       "      <td>159272.4</td>\n",
       "      <td>131603.48</td>\n",
       "      <td>27668.92</td>\n",
       "      <td>13</td>\n",
       "      <td>59158.36</td>\n",
       "      <td>54843.09</td>\n",
       "      <td>4315.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     employer  employment_tenure  gross_monthly_income  loan_release_mo  \\\n",
       "261        29                 11                 56500                2   \n",
       "\n",
       "     loan_release_year  payroll_cut-off  periodic_payment  \\\n",
       "261               2020                3           4550.64   \n",
       "\n",
       "     total_payable_assumed_balance  total_principal  total_interest  \\\n",
       "261                       159272.4        131603.48        27668.92   \n",
       "\n",
       "     no_of_remaining_repayments  outstanding_bal_nov_20  principal  interest  \n",
       "261                          13                59158.36   54843.09   4315.27  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e59d0f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
