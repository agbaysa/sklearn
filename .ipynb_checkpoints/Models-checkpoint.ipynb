{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be15969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# from https://www.kaggle.com/vipulgandhi/a-comprehensive-guide-to-ensemble-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0f3b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90c8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_number</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment_tenure</th>\n",
       "      <th>gross_monthly_income</th>\n",
       "      <th>loan_release_date</th>\n",
       "      <th>loan_release_mo</th>\n",
       "      <th>loan_release_year</th>\n",
       "      <th>payroll_cut-off</th>\n",
       "      <th>periodic_payment</th>\n",
       "      <th>...</th>\n",
       "      <th>_dpd2</th>\n",
       "      <th>_pd90</th>\n",
       "      <th>bucket</th>\n",
       "      <th>restructured_nov_30</th>\n",
       "      <th>_active_pd</th>\n",
       "      <th>status</th>\n",
       "      <th>_new_seasoned</th>\n",
       "      <th>delinquent_reason</th>\n",
       "      <th>last_repayment_paid_nov_20</th>\n",
       "      <th>principal_oustanding_par90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LN096458</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>WNS GLOBAL SERVICES</td>\n",
       "      <td>9</td>\n",
       "      <td>23764</td>\n",
       "      <td>12/30/2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>13 AND 29</td>\n",
       "      <td>1729.22</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>SEPARATED</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1/13/2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LN053391</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>IBIDEN PHILS</td>\n",
       "      <td>6</td>\n",
       "      <td>23868</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>10 AND 25</td>\n",
       "      <td>2163.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10/25/2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LN096940</td>\n",
       "      <td>LOAN ORIGINATIONS</td>\n",
       "      <td>METRO COMBINED LOGISTICS SOLUTIONS, INC.</td>\n",
       "      <td>11</td>\n",
       "      <td>53300</td>\n",
       "      <td>1/12/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 AND 20</td>\n",
       "      <td>4437.67</td>\n",
       "      <td>...</td>\n",
       "      <td>Current</td>\n",
       "      <td>less than 90dpd\\</td>\n",
       "      <td>Current</td>\n",
       "      <td>N</td>\n",
       "      <td>Active</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>New Loan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10/25/2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_number          loan_type                                  employer  \\\n",
       "0    LN096458  LOAN ORIGINATIONS                       WNS GLOBAL SERVICES   \n",
       "1    LN053391  LOAN ORIGINATIONS                              IBIDEN PHILS   \n",
       "2    LN096940  LOAN ORIGINATIONS  METRO COMBINED LOGISTICS SOLUTIONS, INC.   \n",
       "\n",
       "   employment_tenure  gross_monthly_income loan_release_date  loan_release_mo  \\\n",
       "0                  9                 23764        12/30/2020               12   \n",
       "1                  6                 23868         1/13/2021                1   \n",
       "2                 11                 53300         1/12/2021                1   \n",
       "\n",
       "   loan_release_year payroll_cut-off  periodic_payment  ...     _dpd2  \\\n",
       "0               2020       13 AND 29           1729.22  ...   Current   \n",
       "1               2021       10 AND 25           2163.33  ...   Current   \n",
       "2               2021        5 AND 20           4437.67  ...   Current   \n",
       "\n",
       "              _pd90    bucket  restructured_nov_30  _active_pd      status  \\\n",
       "0  less than 90dpd\\   Current                    N      Active   SEPARATED   \n",
       "1  less than 90dpd\\   Current                    N      Active     CURRENT   \n",
       "2  less than 90dpd\\   Current                    N      Active     CURRENT   \n",
       "\n",
       "   _new_seasoned delinquent_reason last_repayment_paid_nov_20  \\\n",
       "0       New Loan           unknown                  1/13/2022   \n",
       "1       New Loan           unknown                 10/25/2021   \n",
       "2       New Loan           unknown                 10/25/2021   \n",
       "\n",
       "  principal_oustanding_par90  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_uploan_nov2021.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f5330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select col types\n",
    "cols_cat = df.select_dtypes(include='object').columns\n",
    "cols_num = df.select_dtypes(include='number').columns\n",
    "\n",
    "cols_X = ['employer', 'employment_tenure','gross_monthly_income', \n",
    "     'loan_release_mo', 'loan_release_year', 'payroll_cut-off', 'periodic_payment',\n",
    "       'total_payable_assumed_balance', 'total_principal', 'total_interest',\n",
    "       'no_of_remaining_repayments', 'outstanding_bal_nov_20', 'principal',\n",
    "       'interest']\n",
    "cols_y = ['target']\n",
    "\n",
    "# Label encoding\n",
    "ln_loan_type = LabelEncoder()\n",
    "ln_employer = LabelEncoder()\n",
    "ln_payroll = LabelEncoder()\n",
    "\n",
    "df['loan_type'] = ln_loan_type.fit_transform(df['loan_type'])\n",
    "df['employer'] = ln_employer.fit_transform(df['employer'])\n",
    "df['payroll_cut-off'] = ln_payroll.fit_transform(df['payroll_cut-off'])\n",
    "\n",
    "# Select X and y\n",
    "X  = df[cols_X]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58dbd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numeric\n",
    "ln_target = LabelEncoder()\n",
    "y = ln_target.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "974252e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3d0d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 180, 0: 49, 1: 36})\n",
      "Counter({2: 46, 0: 12, 1: 9})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4eee4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164179104477612\n",
      "Feature Importance:\n",
      "employer 0.11720558267413946\n",
      "employment_tenure 0.08155488964468935\n",
      "gross_monthly_income 0.04146031402187824\n",
      "loan_release_mo 0.03847925041163239\n",
      "loan_release_year 0.010766755124965692\n",
      "payroll_cut-off 0.054076522383988926\n",
      "periodic_payment 0.060437028160277906\n",
      "total_payable_assumed_balance 0.08435470964960833\n",
      "total_principal 0.060570438422571794\n",
      "total_interest 0.15648496154440814\n",
      "no_of_remaining_repayments 0.06318784697217597\n",
      "outstanding_bal_nov_20 0.08447978835459351\n",
      "principal 0.054575886218060865\n",
      "interest 0.09236602641700957\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Random Forest is an ensemble of Decision Trees.\n",
    "# If we look at a single Decision Tree, important features are likely to appear closer to the root of the \n",
    "# tree, while unimportant features will often appear closer to the leaves (or not at all). It is possible \n",
    "# to get an estimate of a featureâ€™s importance by computing the average depth at which it appears across all \n",
    "# trees in the forest.\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# Feature importance\n",
    "print('Feature Importance:')\n",
    "for name, score in zip(X.columns, model_rf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa9eaded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5970149253731343\n",
      "Feature Importance:\n",
      "employer 0.075\n",
      "employment_tenure 0.02\n",
      "gross_monthly_income 0.035\n",
      "loan_release_mo 0.055\n",
      "loan_release_year 0.04\n",
      "payroll_cut-off 0.015\n",
      "periodic_payment 0.13\n",
      "total_payable_assumed_balance 0.04\n",
      "total_principal 0.065\n",
      "total_interest 0.225\n",
      "no_of_remaining_repayments 0.065\n",
      "outstanding_bal_nov_20 0.03\n",
      "principal 0.105\n",
      "interest 0.1\n"
     ]
    }
   ],
   "source": [
    "# Ada Boost\n",
    "# Boosting refers to a family of algorithms that are able to convert weak learners to strong learners. \n",
    "# The main principle of boosting is to fit a sequence of weak learnersâˆ’ models that are only slightly \n",
    "# better than random guessing, such as small decision trees to weighted versions of the data. More weight \n",
    "# is given to examples that were misclassified by earlier rounds.\n",
    "# The predictions are then combined through a weighted majority vote (classification) or a weighted sum (regression)\n",
    "# to produce the final prediction.\n",
    "\n",
    "# Boosting technique cannot be parallelized (or only partially) because each predictor can only be trained after \n",
    "# the previous predictor has been trained and evaluated. As a result, it does not scale as well as bagging / pasting.\n",
    "\n",
    "# The predictors(classifier/ regressor) fit the training set in sequence. The next predictor corrects its predecessor \n",
    "# by paying more attention to the training instances that the predecessor underfitted. This results in new predictors \n",
    "# focusing more and more on the hard cases.\n",
    "\n",
    "# To build an AdaBoost classifier, each instance's weight is set to an initial value. A base classifier (eg. Decision Tree)\n",
    "# is trained and makes predictions on the training set. The relative weight of misclassified training instances is then \n",
    "# increased. The second classifier is trained on the training set using the updated weights and again it makes predictions\n",
    "# on the training set and update the weights. The algorithm stops when the desired number of predictors is reached, or\n",
    "# when a perfect predictor is found.\n",
    "\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "model_ada.fit(X_train, y_train)\n",
    "y_pred_ada = model_ada.predict(X_test)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, y_pred_ada))\n",
    "\n",
    "# Feature importance\n",
    "print('Feature Importance:')\n",
    "for name, score in zip(X.columns, model_ada.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1f21b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "# Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. \n",
    "# However, instead of tweaking the instance weights at every iteration like AdaBoost, Gradient Boosting tries to \n",
    "# fit the new predictor to the residual errors made by the previous predictor.\n",
    "\n",
    "model_gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "model_gbrt.fit(X_train, y_train)\n",
    "\n",
    "# ...read thru gbr further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26a4cfc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-3efad03b3666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel_et\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel_ada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"SAMME.R\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mmlp_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "# Stacking is an ensemble learning technique that uses predictions from multiple models \n",
    "# (for example decision tree, knn or svm) to build a new model. This model is used for making \n",
    "# predictions on the test set.\n",
    "\n",
    "# First, the training set is split in two subsets. The first subset is used to train the predictors in the first \n",
    "# layer. Next, the predictors in the first layer are used to make predictions on the second(hold-out) set. \n",
    "# Now (in example above) for each instance in the hold-out set there are four predicted values. A new \n",
    "# training set is created using these predicted values as input features and keeping the target values. \n",
    "# The blender is trained on this new training set, it learns to predict the target value where inputs are \n",
    "# the the first layerâ€™s predictions.\n",
    "\n",
    "# It is possible to train several different blenders on the top of one another (e.g., one using Linear \n",
    "# Regression, another using Random Forest Regression etc). The training set should be divided equal to the number of layers(see image above).\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "model_et = ExtraTreesClassifier(n_estimators=10, random_state=1)\n",
    "model_ada = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "estimators = [model_rf, model_et, model_xgb, mlp_clf]\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "\n",
    "[estimator.score(X_test, y_test) for estimator in estimators]\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "\n",
    "model_rf_blend = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "model_rf_blend.fit(X_test_predictions, y_test)\n",
    "\n",
    "print('OOB Score: %s' %model_rf_blend.oob_score_)\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_pred = model_rf_blend.predict(X_test_predictions)\n",
    "print('Accuracy Score: %s' %accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b291a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.49336356429261485\n",
      "R2: 0.18875126735914005\n"
     ]
    }
   ],
   "source": [
    "# Linear Model\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_ln = linear_model.LinearRegression()\n",
    "model_ln.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "predict_ln = model_ln.predict(X_test)\n",
    "\n",
    "print('MSE: %s' %mean_squared_error(y_test, predict_ln))\n",
    "print('R2: %s' %r2_score(y_test, predict_ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad75e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.18746924869674975\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Cannot handle multi-class\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_ridge = linear_model.Ridge(alpha=0.5)\n",
    "print('Score: {}'.format(model_ridge.fit(X_train, y_train).score(X_test, y_test)))\n",
    "\n",
    "predict_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "model_ridge.coef_\n",
    "\n",
    "# RidgeCV implements ridge regression with built-in cross-validation of the alpha parameter. \n",
    "# The object works in the same way as GridSearchCV except that it defaults to Leave-One-Out Cross-Validation:\n",
    "\n",
    "model_ridge_cv = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "model_ridge_cv.fit(X_train, y_train).score(X_test, y_test)\n",
    "model_ridge_cv.alpha_\n",
    "np.logspace(-6, 6, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e34164a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7164179104477612\n",
      "Accuracy: 0.7164179104477612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07379902, -0.16192602,  0.0464226 , -0.18013795, -0.44216748,\n",
       "         0.05326037,  0.75546178, -0.86393837, -0.88852682, -0.70140485,\n",
       "        -0.04682424,  0.60887214,  0.63777945,  0.4988921 ],\n",
       "       [-0.19148143, -0.04393293,  0.0687405 , -0.02980247,  0.03522763,\n",
       "        -0.10922648, -0.46143511,  0.33291434,  0.29341233,  0.34291441,\n",
       "        -0.17037679, -0.13244197, -0.02855827, -0.33483381],\n",
       "       [ 0.26528045,  0.20585895, -0.1151631 ,  0.20994042,  0.40693985,\n",
       "         0.05596611, -0.29402667,  0.53102403,  0.59511449,  0.35849045,\n",
       "         0.21720103, -0.47643017, -0.60922117, -0.16405829]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RidgeClassifier!!!\n",
    "#...fit transform first...\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "fit_ss = scaler.fit(X_test)\n",
    "X_train_scaled = pd.DataFrame(fit_ss.transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(fit_ss.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "model_ridge_clf = linear_model.RidgeClassifier()\n",
    "print(model_ridge_clf.fit(X_train_scaled, y_train).score(X_test_scaled, y_test))\n",
    "\n",
    "predict_ridge_clf = model_ridge_clf.predict(X_test_scaled)\n",
    "print('Accuracy: %s' %accuracy_score(y_test, predict_ridge_clf))\n",
    "model_ridge_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6dd1e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164179104477612"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent on Linear Models\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_sgb = make_pipeline(scaler, linear_model.SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model_sgb.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "model_ridge_clf = make_pipeline(scaler, linear_model.RidgeClassifier())\n",
    "model_ridge_clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "predict_ridge_clf = model_ridge_clf.predict(X_test)\n",
    "accuracy_score(y_test, predict_ridge_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee470c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test commit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a88e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\adria\\\\Documents\\\\agb_github\\\\sklearn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3a089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349990a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461f61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
